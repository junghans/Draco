#! /usr/bin/env python
# -*- mode: Python -*-

"""Descends the tree looking for .log files. Parses for failures and
produces a log with filenames, processor numbers and line numbers.
"""

import re

import FileUtils
import os
import commands

##---------------------------------------------------------------------------##
def get_local_logfiles(dir):
    """ Creates a generator for all files matching *.log. Generates
    open file handles.
    """
    files = FileUtils.gen_find("*.log", dir)
    return FileUtils.gen_open(files)


##---------------------------------------------------------------------------##
# Pattern and key values for log filenames
logfile_pattern = re.compile(".*/src/(?P<component>\w+)"
                             "/test/"
                             "(?P<test>\w+)-(?P<procs>\d+).log")
logfile_keys = logfile_pattern.groupindex.keys()

##---------------------------------------------------------------------------##
# Patterns for failures and assertions in log files. 
failure_test = re.compile("Test: failed on line (?P<line>\d+)")
assert_test  = re.compile("Assertion: (?P<assert>.+)?, failed in "
                          "(?P<file>\S+), line (?P<line>\d+)\.")
error_test   = re.compile(r"ERROR: While testing (?P<test>\S+)?," 
                          r"(?P<error>.+?)?, "
                          r"failed in (?P<file>[.|/|_|\w]+?), "
                          r"line (?P<line>\d+)\.") 
                        

##---------------------------------------------------------------------------##
def extract_errors(open_files):
    """ This generator yields successive matches of failures in a
    collection of open files. The open files are tested against the
    pattern for log files first.
    """

    for file in open_files:

        logfile_match = logfile_pattern.match(file.name)
        if not logfile_match: continue

        for line in file:

            problem_match = failure_test.search(line) or \
                assert_test.search(line)

            if problem_match:
                result = problem_match.groupdict()
                result.update(logfile_match.groupdict())
                yield result

            error_match = error_test.search(line)

            if error_match:
                result = error_match.groupdict()
                result.update(logfile_match.groupdict())
                file.next()
                result["assert"] = file.next().strip()
                yield result

##---------------------------------------------------------------------------##
if __name__=="__main__":

    # Generate all of the errors in all of the logfiles:
    log_files  = get_local_logfiles(os.getcwd())
    all_errors = extract_errors(log_files)


    # Build two dictionaries of failures and assertions from the error
    # stream. 
    failures={}
    assertions={}
    for error in all_errors:

        key = (error["component"], error["test"])

        if error.has_key("assert"):
            assertions[key] = error
        else:
            failures.setdefault(key, set()).add(error["line"])



            
    # Display each error with a sorted list of line numbers
    if failures: print "Test failures:"
    else: print "No failures"
    contents = []
    for (test, lines) in failures.items():
        lines = map(int, lines)
        lines.sort()
        lines = map(str, lines)
        contents.append( (test[0], test[1], lines) )
    
    contents.sort()
    print "\n".join(["%20s %40s failed on lines: %s" % \
                     (c[0], c[1], ", ".join(c[2])) for c in contents]   )
    print "\n"




    # Display the assertions
    contents = []
    if assertions: print "Assertions:"
    else: print "No assertions"
    for (test, assertion) in assertions.items():
        contents.append((test[0], test[1], 
                         assertion["assert"], assertion["file"], assertion["line"]))
        
    contents.sort()
    print "\n".join(["%20s %40s generated assertion: %s in file: %s "
                    "line: %s" % c for c in contents])




